{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deploying_Transformer_Models_Japanese_Bert.ipynb","provenance":[{"file_id":"1Q6YOo7iuvEYOclv1iEqaZnf99zgEvmu1","timestamp":1621497258989},{"file_id":"1GCnqbpSq41eF_FBOfudz1RtFFE1t_qBm","timestamp":1620811299967}],"collapsed_sections":[],"authorship_tag":"ABX9TyNAuGSnUhvpp1bzjAJslqZW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"p5nc2jhdz9Z-"},"source":["## [Running Flask and FastAPI on Google Colab](https://medium.datadriveninvestor.com/flask-on-colab-825d2099d9d8)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4oXyBEQLzjXy","executionInfo":{"status":"ok","timestamp":1621497299016,"user_tz":-540,"elapsed":11368,"user":{"displayName":"加納邦彦","photoUrl":"","userId":"06233728671996802409"}},"outputId":"37e26fda-a7fb-4685-f9d2-5d2069ee3fcd"},"source":["!pip install fastapi nest-asyncio pyngrok uvicorn"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting fastapi\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/b9/a91a699f5c201413b3f61405dbccc29ebe5ad25945230e9cec98fdb2434c/fastapi-0.65.1-py3-none-any.whl (50kB)\n","\r\u001b[K     |██████▍                         | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 20kB 9.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 30kB 8.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 40kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.2MB/s \n","\u001b[?25hRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.1)\n","Collecting pyngrok\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/4e/a2fe095bbe17cf26424c4abcd22a0490e22d01cc628f25af5e220ddbf6f0/pyngrok-5.0.5.tar.gz (745kB)\n","\u001b[K     |████████████████████████████████| 747kB 7.3MB/s \n","\u001b[?25hCollecting uvicorn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/de/953f0289508b1b92debdf0a6822d9b88ffb0c6ad471d709cf639a2c8a176/uvicorn-0.13.4-py3-none-any.whl (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n","\u001b[?25hCollecting starlette==0.14.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/34/db1890f442a1cd3a2c761f4109a0eb4e63503218d70a8c8e97faa09a5500/starlette-0.14.2-py3-none-any.whl (60kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.2MB/s \n","\u001b[?25hCollecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f2/2d5425efe57f6c4e06cbe5e587c1fd16929dcf0eb90bd4d3d1e1c97d1151/pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1MB)\n","\u001b[K     |████████████████████████████████| 10.1MB 12.2MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from uvicorn) (3.7.4.3)\n","Collecting h11>=0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/0f/7a0eeea938eaf61074f29fed9717f2010e8d0e0905d36b38d3275a1e4622/h11-0.12.0-py3-none-any.whl (54kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n","\u001b[?25hCollecting click==7.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n","\u001b[K     |████████████████████████████████| 92kB 9.1MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-5.0.5-cp37-none-any.whl size=19246 sha256=4af281d4af546b3713f56a91856abcf24e0ab6d6e31902d0eabd15be4893ef02\n","  Stored in directory: /root/.cache/pip/wheels/0c/13/64/5ebbcc22eaf53fdf5766b397c1fb17c83f5775fdccf0ea1b88\n","Successfully built pyngrok\n","Installing collected packages: starlette, pydantic, fastapi, pyngrok, h11, click, uvicorn\n","  Found existing installation: click 8.0.0\n","    Uninstalling click-8.0.0:\n","      Successfully uninstalled click-8.0.0\n","Successfully installed click-7.1.2 fastapi-0.65.1 h11-0.12.0 pydantic-1.8.2 pyngrok-5.0.5 starlette-0.14.2 uvicorn-0.13.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOpgIOjwzqPs","executionInfo":{"status":"ok","timestamp":1621497329937,"user_tz":-540,"elapsed":14457,"user":{"displayName":"加納邦彦","photoUrl":"","userId":"06233728671996802409"}},"outputId":"e661e034-0412-4fbe-bd33-04acabae1343"},"source":["from fastapi import FastAPI\n","import nest_asyncio\n","from pyngrok import ngrok\n","import uvicorn\n","\n","app = FastAPI()\n","\n","@app.get('/index')\n","async def home():\n","  return \"Hello World\"\n","\n","ngrok_tunnel = ngrok.connect(8000)\n","print('Public URL:', ngrok_tunnel.public_url)\n","print('Public docs URL:', ngrok_tunnel.public_url + \"/docs\")\n","nest_asyncio.apply()\n","uvicorn.run(app, port=8000)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":[""],"name":"stdout"},{"output_type":"stream","text":["INFO:     Started server process [59]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":["Public URL: http://13a7db702ebc.ngrok.io\n","Public docs URL: http://13a7db702ebc.ngrok.io/docs\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:     Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:     Finished server process [59]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Ivofnr0T0PbA"},"source":["## [Deploying Transformer Models](https://chatbotslife.com/deploying-transformer-models-1350876016f)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LwMcyVaxfig","executionInfo":{"status":"ok","timestamp":1621497379267,"user_tz":-540,"elapsed":41757,"user":{"displayName":"加納邦彦","photoUrl":"","userId":"06233728671996802409"}},"outputId":"515ee0c9-bdf8-4c73-8349-6acd9baac33e"},"source":["%%bash\n","pip install -qq transformers\n","#pip install torch torchvision\n","pip install \"fugashi[unidic-lite]\" \n","pip install ipadic"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting fugashi[unidic-lite]\n","  Downloading https://files.pythonhosted.org/packages/55/9c/009da34dd111e84f54eef833c84afb5c744a0306af8546014a958e1967a0/fugashi-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (486kB)\n","Collecting unidic-lite; extra == \"unidic-lite\"\n","  Downloading https://files.pythonhosted.org/packages/55/2b/8cf7514cb57d028abcef625afa847d60ff1ffbf0049c36b78faa7c35046f/unidic-lite-1.0.8.tar.gz (47.4MB)\n","Building wheels for collected packages: unidic-lite\n","  Building wheel for unidic-lite (setup.py): started\n","  Building wheel for unidic-lite (setup.py): finished with status 'done'\n","  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-cp37-none-any.whl size=47658825 sha256=157022620f15e35c3d06b6734a8c565734002f50fea16b49ca9e3c2d727ed352\n","  Stored in directory: /root/.cache/pip/wheels/20/48/8d/b66d8361a27f58f41ec86640e4fd2640de0403a6367511eab7\n","Successfully built unidic-lite\n","Installing collected packages: unidic-lite, fugashi\n","Successfully installed fugashi-1.1.0 unidic-lite-1.0.8\n","Collecting ipadic\n","  Downloading https://files.pythonhosted.org/packages/e7/4e/c459f94d62a0bef89f866857bc51b9105aff236b83928618315b41a26b7b/ipadic-1.0.0.tar.gz (13.4MB)\n","Building wheels for collected packages: ipadic\n","  Building wheel for ipadic (setup.py): started\n","  Building wheel for ipadic (setup.py): finished with status 'done'\n","  Created wheel for ipadic: filename=ipadic-1.0.0-cp37-none-any.whl size=13556725 sha256=0f6ed3d878443e0a3a0e7c27a0112e3f2f2915ee74ac14fe3971e74fe2658501\n","  Stored in directory: /root/.cache/pip/wheels/ff/00/d1/0c094a0ce58a77199a0c5801f0ecf510c80f0ecbec27f07d2c\n","Successfully built ipadic\n","Installing collected packages: ipadic\n","Successfully installed ipadic-1.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2GM7osRFyEm4","executionInfo":{"status":"ok","timestamp":1621498651362,"user_tz":-540,"elapsed":1154,"user":{"displayName":"加納邦彦","photoUrl":"","userId":"06233728671996802409"}}},"source":["import torch\n","from transformers import (\n","    pipeline,\n","    AutoModelForMaskedLM,\n","    AutoTokenizer\n",")\n","\n","class NLP:\n","    def __init__(self):\n","        self.gen_tokenizer = AutoTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n","        self.gen_model = AutoModelForMaskedLM.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n","         \n","    def generate(self, prompt=\"The epistemelogical limit\"):\n","        #inputs = self.gen_tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n","        #with torch.no_grad():\n","        #    summary_ids = self.gen_model.generate(inputs) #, max_length=512, min_length=5, length_penalty=5., num_beams=2)\n","        #    summary = self.gen_tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","        #    return summary\n","\n","        # 入力テキストのエンコード\n","        input_ids = self.gen_tokenizer.encode(f'吾輩は{self.gen_tokenizer.mask_token}である。名前はまだ無い。', return_tensors='pt', max_length=512, truncation=True)\n","        #input_ids = self.gen_tokenizer.encode(prompt, return_tensors='pt', max_length=512, truncation=True)\n","        print('input_ids:', self.gen_tokenizer.convert_ids_to_tokens(input_ids[0].tolist()))\n","        \n","        # マスクインデックスの取得\n","        masked_index = torch.where(input_ids == self.gen_tokenizer.mask_token_id)[1].tolist()[0]\n","        print('masked_index:', masked_index)\n","        \n","        # マスクトークンの予測\n","        result = self.gen_model(input_ids)\n","        pred_ids = result[0][:, masked_index].topk(5).indices.tolist()[0]\n","\n","        output = []\n","        for pred_id in pred_ids:\n","            output_ids = input_ids.tolist()[0]\n","            output_ids[masked_index] = pred_id\n","            #print(self.gen_tokenizer.decode(output_ids))\n","            #print(self.gen_tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True))\n","            output.append(self.gen_tokenizer.decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True))\n","        return output\n"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cn9x1pbvyJoH","executionInfo":{"status":"ok","timestamp":1621498718351,"user_tz":-540,"elapsed":7356,"user":{"displayName":"加納邦彦","photoUrl":"","userId":"06233728671996802409"}},"outputId":"ae6bdc74-a4c4-4526-cc3c-ad1497d8bf36"},"source":["# from nlp import NLP\n","nlp = NLP()\n","#print(nlp.sentiments(\"うほほーい、大好き♡\"))\n","for s in nlp.generate():\n","    print(s)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["input_ids: ['[CLS]', '吾', '##輩', 'は', '[MASK]', 'で', 'ある', '。', '名前', 'は', 'まだ', '無い', '。', '[SEP]']\n","masked_index: 4\n","吾輩 は 猫 で ある 。 名前 は まだ 無い 。\n","吾輩 は 犬 で ある 。 名前 は まだ 無い 。\n","吾輩 は 人間 で ある 。 名前 は まだ 無い 。\n","吾輩 は 狼 で ある 。 名前 は まだ 無い 。\n","吾輩 は 私 で ある 。 名前 は まだ 無い 。\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdKeGe9wycSZ","executionInfo":{"status":"ok","timestamp":1621498985887,"user_tz":-540,"elapsed":131175,"user":{"displayName":"加納邦彦","photoUrl":"","userId":"06233728671996802409"}},"outputId":"8e1eb24c-b3dd-4f4b-de8a-926fe4ff79b1"},"source":["from fastapi import FastAPI\n","from fastapi.middleware.cors import CORSMiddleware\n","from pydantic import BaseModel\n","#from app.nlp import NLP\n","import nest_asyncio\n","from pyngrok import ngrok\n","import uvicorn\n","\n","class Message(BaseModel):\n","    input: str\n","    output: str = None\n","\n","app = FastAPI()\n","nlp = NLP()\n","\n","origins = [\n","    \"http://localhost\",\n","    \"http://localhost:3000\",\n","    \"http://127.0.0.1:3000\"\n","]\n","\n","app.add_middleware(\n","    CORSMiddleware,\n","    allow_origins=origins,\n","    allow_credentials=True,\n","    allow_methods=[\"POST\"],\n","    allow_headers=[\"*\"],\n",")\n","\n","@app.post(\"/generative/\")\n","async def  generate(message: Message):\n","    message.output  = nlp.generate(prompt=message.input)\n","    return {\"output\" : message.output}\n","\n","ngrok_tunnel = ngrok.connect(8000)\n","print('Public URL:', ngrok_tunnel.public_url)\n","print('Public docs URL:', ngrok_tunnel.public_url + \"/docs\")\n","nest_asyncio.apply()\n","uvicorn.run(app, port=8000)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"],"name":"stderr"},{"output_type":"stream","text":["Public URL: http://5d97a0bc7adc.ngrok.io\n","Public docs URL: http://5d97a0bc7adc.ngrok.io/docs\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:     Started server process [59]\n","INFO:     Waiting for application startup.\n","INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:     124.32.186.1:0 - \"GET /docs HTTP/1.1\" 200 OK\n","INFO:     124.32.186.1:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n","input_ids: ['[CLS]', '吾', '##輩', 'は', '[MASK]', 'で', 'ある', '。', '名前', 'は', 'まだ', '無い', '。', '[SEP]']\n","masked_index: 4\n","INFO:     124.32.186.1:0 - \"POST /generative/ HTTP/1.1\" 200 OK\n","INFO:     124.32.186.1:0 - \"POST /generative/ HTTP/1.1\" 422 Unprocessable Entity\n","input_ids: ['[CLS]', '吾', '##輩', 'は', '[MASK]', 'で', 'ある', '。', '名前', 'は', 'まだ', '無い', '。', '[SEP]']\n","masked_index: 4\n","INFO:     124.32.186.1:0 - \"POST /generative/ HTTP/1.1\" 200 OK\n","input_ids: ['[CLS]', '吾', '##輩', 'は', '[MASK]', 'で', 'ある', '。', '名前', 'は', 'まだ', '無い', '。', '[SEP]']\n","masked_index: 4\n","INFO:     124.32.186.1:0 - \"POST /generative/ HTTP/1.1\" 200 OK\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:     Shutting down\n","INFO:     Waiting for application shutdown.\n","INFO:     Application shutdown complete.\n","INFO:     Finished server process [59]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"bfz6d54A1cc3"},"source":["```\n","% curl -X 'POST' \\\n","  'http://5d97a0bc7adc.ngrok.io/generative/' \\\n","  -H 'accept: application/json' \\\n","  -H 'Content-Type: application/json' \\\n","  -d '{\n","  \"input\": \"\",\n","  \"output\": \"\"\n","}'\n","\n","{\"output\":[\"吾輩 は 猫 で ある 。 名前 は まだ 無い 。\",\"吾輩 は 犬 で ある 。 名前 は まだ 無い 。\",\"吾輩 は 人間 で ある 。 名前 は まだ 無い 。\",\"吾輩 は 狼 で ある 。 名前 は まだ 無い 。\",\"吾輩 は 私 で ある 。 名前 は まだ 無い 。\"]}\n","```"]}]}